{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport nltk  \nnltk.download('stopwords') \nfrom nltk.corpus import stopwords \nfrom nltk.stem.porter import PorterStemmer \nfrom wordcloud import WordCloud, STOPWORDS\nfrom string import punctuation\nfrom collections import Counter","execution_count":85,"outputs":[{"output_type":"stream","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/nlp-getting-started/train.csv\")\n\nprint(\"The csv shape: \", str(train_df.shape))\ntrain_df.head()\n","execution_count":86,"outputs":[{"output_type":"stream","text":"The csv shape:  (7613, 5)\n","name":"stdout"},{"output_type":"execute_result","execution_count":86,"data":{"text/plain":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\" Example text: \", str(train_df[\"text\"][1]), \"\\n\", \"Target: \", str(train_df[\"target\"][1]))","execution_count":87,"outputs":[{"output_type":"stream","text":" Example text:  Forest fire near La Ronge Sask. Canada \n Target:  1\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"total = train_df.isnull().sum().sort_values(ascending = False)\npercent = (train_df.isnull().sum())/(train_df.isnull().count()).sort_values(ascending = False)\n\nmissing_data = pd.concat([total, percent], axis = 1, keys = [\"total\", \"percent\"])\nmissing_data\n","execution_count":88,"outputs":[{"output_type":"execute_result","execution_count":88,"data":{"text/plain":"          total   percent\nlocation   2533  0.332720\nkeyword      61  0.008013\ntarget        0  0.000000\ntext          0  0.000000\nid            0  0.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>total</th>\n      <th>percent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>location</th>\n      <td>2533</td>\n      <td>0.332720</td>\n    </tr>\n    <tr>\n      <th>keyword</th>\n      <td>61</td>\n      <td>0.008013</td>\n    </tr>\n    <tr>\n      <th>target</th>\n      <td>0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>text</th>\n      <td>0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>id</th>\n      <td>0</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df.drop([\"keyword\", \"location\", \"id\"], axis = 1)\nprint(\"Keyword, Location, and id are all dropped successfully\")\n\n","execution_count":89,"outputs":[{"output_type":"stream","text":"Keyword, Location, and id are all dropped successfully\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"phrase = \"Hello,,?? This is my Tweet!!!. I also want you to read this tweet https://www.youtube.com and also note https://relentless.com\"\npunct_list = set(punctuation)\n\n\ndef remove_punct(text):\n    \n    new_text = \"\".join(ch for ch in text if ch not in punct_list)\n    return new_text\n\ndef remove_stopwords(text):\n    \n    text_split = text.split(\" \")\n    text = [word for word in text_split if word not in STOPWORDS]\n    return text\n\ndef remove_http(text_list):\n    \n    new_text = [word for word in text_list if word.find(\"http\") == -1]\n    return new_text\n    \n\n\nremove_http(remove_stopwords(remove_punct(phrase.lower())))","execution_count":90,"outputs":[{"output_type":"execute_result","execution_count":90,"data":{"text/plain":"['hello', 'tweet', 'want', 'read', 'tweet', 'note']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_text(text):\n    \n    text = remove_http(remove_stopwords(remove_punct(text.lower())))\n    return text\n\npreprocess_text(phrase)\ntrain_df[\"text\"] = train_df[\"text\"].apply(lambda x: preprocess_text(x))","execution_count":91,"outputs":[{"output_type":"execute_result","execution_count":91,"data":{"text/plain":"['hello', 'tweet', 'want', 'read', 'tweet', 'note']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The new preprocessed data\ntrain_df.head()","execution_count":100,"outputs":[{"output_type":"execute_result","execution_count":100,"data":{"text/plain":"                                                text  target\n0  [deeds, reason, earthquake, may, allah, forgiv...       1\n1      [forest, fire, near, la, ronge, sask, canada]       1\n2  [residents, asked, shelter, place, notified, o...       1\n3  [13000, people, receive, wildfires, evacuation...       1\n4  [got, sent, photo, ruby, alaska, smoke, wildfi...       1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[deeds, reason, earthquake, may, allah, forgiv...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[residents, asked, shelter, place, notified, o...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[13000, people, receive, wildfires, evacuation...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[got, sent, photo, ruby, alaska, smoke, wildfi...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"text\"]","execution_count":102,"outputs":[{"output_type":"execute_result","execution_count":102,"data":{"text/plain":"0       [deeds, reason, earthquake, may, allah, forgiv...\n1           [forest, fire, near, la, ronge, sask, canada]\n2       [residents, asked, shelter, place, notified, o...\n3       [13000, people, receive, wildfires, evacuation...\n4       [got, sent, photo, ruby, alaska, smoke, wildfi...\n                              ...                        \n7608    [two, giant, cranes, holding, bridge, collapse...\n7609    [ariaahrary, thetawniest, control, wild, fires...\n7610             [m194, 0104, utc5km, s, volcano, hawaii]\n7611    [police, investigating, ebike, collided, car, ...\n7612    [latest, homes, razed, northern, california, w...\nName: text, Length: 7613, dtype: object"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Turn the text into numbers\n\nfreq = {}\nfor row in train_df[\"text\"]:\n    \n    for word in row:\n        if word in freq:\n            freq[word] += 1\n        else:\n            freq[word] = 1\n\nprint(freq)","execution_count":104,"outputs":[{"output_type":"stream","text":"{'the': 7613, 'latest:': 7613, 'more': 7613, 'homes': 7613, 'razed': 7613, 'by': 7613, 'northern': 7613, 'california': 7613, 'wildfire': 7613, '-': 7613, 'abc': 7613, 'news': 7613, 'http://t.co/ymy4rskq3d': 7613}\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Now I have to create a generator where:\n* input: define length of padded array that contains the tweet\n* label: whether that tweet needs action or not."}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}